# VoxCPM 项目进度汇报

## 1. 项目概述
本项目基于 **VoxCPM (Voice Cloning & Processing Model)** 构建了一套高性能的语音合成与克隆系统。该系统利用先进的无 Tokenizer 扩散自回归架构，能够生成极具表现力的语音，并支持只需数秒参考音频的零样本声音克隆（Zero-shot Voice Cloning）。

我们的目标是打造一个**高保真、低延迟、音色稳定**的实时语音交互后端。

## 2. 核心功能
*   **高保真语音合成**: 支持 44.1kHz 采样率的超清语音生成。
*   **实时流式输出 (Streaming)**: 支持 WebSocket 流式传输，首包延迟极低，满足实时对话需求。
*   **声音克隆**: 仅需一段简短的参考音频，即可复刻目标说话人的音色、语调和情感。
*   **API 服务**: 提供标准的 HTTP 和 WebSocket 接口，集成了 ASR（语音识别）和 VAD（语音检测）能力。

## 3. 近期工作进展 (优化与修复)

针对原版模型在长文本生成和流式对话中遇到的痛点，我们完成了以下核心优化：

### 3.1 解决长文本音色漂移问题
*   **问题描述**: 在合成长段文本时，模型容易出现音色不稳定的情况（如"一段话中男声女声混杂"）。
*   **解决方案**:
    *   **智能文本切分**: 实现了基于标点符号的智能分句算法，确保模型每次只处理完整的语义单元，保持注意力集中。
    *   **增量式 Prompt Cache**: 开发了音色锁定机制。对于长文本，提取第一句生成的音频特征作为后续句子的基准（Anchor），强制后续生成保持同一音色特征，彻底解决了音色跳变问题。

### 3.2 增强 WebSocket 流式接口
*   **问题描述**: 原生 WebSocket 接口不支持复用已生成的音色缓存，导致多轮对话中音色难以统一。
*   **解决方案**:
    *   **Cache ID 支持**: 在 WebSocket 协议中增加了 `prompt_cache_id` 参数。前端可以在首轮对话后获取音色 ID，并在后续对话中复用，大大降低了重复计算开销（无需每次重新编码参考音频），同时保证了对话全过程音色的一致性。
    *   **流式协议优化**: 优化了 PCM 数据流的传输逻辑，适配了前端播放器需求。

### 3.3 微调 (Fine-tuning) 方案落地
*   **方案验证**: 验证了 LoRA (Low-Rank Adaptation) 微调方案的可行性。
*   **应用场景**: 针对特定专属音色（如固定客服声音），配置了 LoRA 训练脚本。相比 Zero-shot 克隆，LoRA 微调能提供生产级的音色稳定性。

## 4. 技术架构
*   **模型层**: VoxCPM 1.5 (800M 参数), AudioVAE, SenseVoice (ASR)
*   **服务层**: FastAPI, WebSocket
*   **部署环境**: Linux / NVIDIA GPU (CUDA)

## 5. 下一步计划
*   **模型微调**: 采集特定目标人声数据，训练专属 LoRA 模型以获得极致稳定的效果。
*   **全链路集成**: 将当前的 TTS 服务与大语言模型 (LLM) 深度串联，实现端到端的实时语音对话机器人。
